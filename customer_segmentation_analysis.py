# -*- coding: utf-8 -*-
"""Customer Segmentation Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rsA49zj77nn7D6SWSI4_NeWIiNpqE9xL
"""

!pip install pandas numpy matplotlib seaborn scikit-learn openpyxl

import pandas as pd

# Load dataset
df = pd.read_excel('Online Retail.xlsx', engine='openpyxl')

# Display the first few rows
print(df.head())

# Remove rows with missing CustomerID
df_cleaned = df.dropna(subset=['CustomerID'])

# Remove rows with negative quantities
df_cleaned = df_cleaned[df_cleaned['Quantity'] > 0]

# Create a new column 'TotalAmount' = Quantity * UnitPrice
df_cleaned['TotalAmount'] = df_cleaned['Quantity'] * df_cleaned['UnitPrice']

df_cleaned['InvoiceDate'] = pd.to_datetime(df_cleaned['InvoiceDate'])

import matplotlib.pyplot as plt

# Group by 'Country' and sum the 'TotalAmount'
country_sales = df_cleaned.groupby('Country')['TotalAmount'].sum().sort_values(ascending=False).head(10)

# Plot top 10 countries
country_sales.plot(kind='bar', figsize=(10, 6))
plt.title('Top 10 Countries by Sales')
plt.ylabel('Total Sales')
plt.show()

# Group by 'Description' and sum the 'Quantity'
popular_products = df_cleaned.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)

# Plot popular products
popular_products.plot(kind='bar', figsize=(10, 6))
plt.title('Top 10 Most Popular Products')
plt.ylabel('Quantity Sold')
plt.show()

import datetime as dt

# Set snapshot date to calculate recency (usually the most recent date in the dataset)
snapshot_date = df_cleaned['InvoiceDate'].max() + dt.timedelta(days=1)

# Calculate Recency, Frequency, and Monetary (RFM)
rfm = df_cleaned.groupby('CustomerID').agg({
    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,  # Recency
    'InvoiceNo': 'nunique',  # Frequency
    'TotalAmount': 'sum'  # Monetary
}).reset_index()

# Rename the columns
rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']

# Display the RFM table
print(rfm.head())

from sklearn.preprocessing import StandardScaler

# Standardize the RFM values
scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm[['Recency', 'Frequency', 'Monetary']])

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Elbow method to find the optimal number of clusters
sse = {}
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(rfm_scaled)
    sse[k] = kmeans.inertia_

# Plot the SSE for different k values
plt.figure(figsize=(10, 6))
plt.plot(list(sse.keys()), list(sse.values()), 'bx-')
plt.xlabel('Number of clusters (k)')
plt.ylabel('SSE')
plt.title('Elbow Method to Find Optimal k')
plt.show()

# Fit KMeans with the chosen number of clusters
kmeans = KMeans(n_clusters=4, random_state=42)
rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)

# View the clusters
print(rfm.groupby('Cluster').mean())

rfm.to_csv('customer_segments.csv', index=False)